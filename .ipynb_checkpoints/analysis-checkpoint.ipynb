{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import codecs\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('little_women.txt', 'r', errors = 'ignore') as f:\n",
    "    text = f.read()\n",
    "original_text = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stop_words.txt', 'r', errors = 'ignore') as f:\n",
    "    stop_words = f.read()\n",
    "stop_words = stop_words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = decontracted(text)\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+' , ' ', text)\n",
    "    text = text.lower()\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTotalNumberOfWords(text):\n",
    "    words = text.split(' ')\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words:  191003\n"
     ]
    }
   ],
   "source": [
    "num_words = getTotalNumberOfWords(text)\n",
    "print('Number of words: ', str(num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTotalUniqueWords(text):\n",
    "    words = text.split(' ')\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words:  11778\n"
     ]
    }
   ],
   "source": [
    "unique_words = getTotalUniqueWords(text)\n",
    "print('Number of unique words: ' , str(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get20MostFrequentWords(text):\n",
    "    words = text.split(' ')\n",
    "    word_freq = {}\n",
    "    for word in words:\n",
    "        if word not in word_freq.keys():\n",
    "            word_freq[word] = 1\n",
    "        else:\n",
    "            word_freq[word] += 1\n",
    "    top_20 = sorted(word_freq, key = word_freq.get, reverse = True)[:20]\n",
    "    top_20_freq = []\n",
    "    for word in top_20:\n",
    "        top_20_freq.append([word, word_freq[word]])\n",
    "    return top_20_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words with frequency are: \n",
      "and 7909\n",
      "the 7112\n",
      "to 5019\n",
      "a 4325\n",
      "I 4003\n",
      "of 3354\n",
      "her 3192\n",
      "not 2531\n",
      "in 2377\n",
      "it 2324\n",
      "is 2321\n",
      "for 2147\n",
      "you 2069\n",
      "was 2062\n",
      "she 2004\n",
      "as 1875\n",
      "that 1779\n",
      "with 1771\n",
      "Jo 1355\n",
      "he 1342\n"
     ]
    }
   ],
   "source": [
    "top_20 = get20MostFrequentWords(text)\n",
    "print('Top 20 words with frequency are: ')\n",
    "for word, freq in top_20:\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get20MostInterestingFrequentWords(text):\n",
    "    words = text.split(' ')\n",
    "    stop_words_100 = random.sample(stop_words, 100)\n",
    "    word_freq = {}\n",
    "    for word in words:\n",
    "        if word in stop_words_100:\n",
    "            continue\n",
    "        if word not in word_freq.keys():\n",
    "            word_freq[word] = 1\n",
    "        else:\n",
    "            word_freq[word] += 1\n",
    "    top_20 = sorted(word_freq, key = word_freq.get, reverse = True)[:20]\n",
    "    top_20_freq = []\n",
    "    for word in top_20:\n",
    "        top_20_freq.append([word, word_freq[word]])\n",
    "    return top_20_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 interesting words are: \n",
      "and 7909\n",
      "the 7112\n",
      "to 5019\n",
      "a 4325\n",
      "I 4003\n",
      "of 3354\n",
      "her 3192\n",
      "not 2531\n",
      "in 2377\n",
      "it 2324\n",
      "is 2321\n",
      "for 2147\n",
      "she 2004\n",
      "as 1875\n",
      "that 1779\n",
      "with 1771\n",
      "Jo 1355\n",
      "he 1342\n",
      "but 1257\n",
      "his 1097\n"
     ]
    }
   ],
   "source": [
    "top_20_interesting = get20MostInterestingFrequentWords(text)\n",
    "print('Top 20 interesting words are: ')\n",
    "for word, freq in top_20_interesting:\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get20LeastFrequentWords(text):\n",
    "    words = text.split(' ')\n",
    "    word_freq = {}\n",
    "    for word in words:\n",
    "        if word not in word_freq.keys():\n",
    "            word_freq[word] = 1\n",
    "        else:\n",
    "            word_freq[word] += 1\n",
    "    top_20 = sorted(word_freq, key = word_freq.get)[:20]\n",
    "    top_20_freq = []\n",
    "    for word in top_20:\n",
    "        top_20_freq.append([word, word_freq[word]])\n",
    "    return top_20_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 least used words are: \n",
      "PLAYING 1\n",
      "PILGRIMS 1\n",
      "Sintran_ 1\n",
      "Faber 1\n",
      "libel 1\n",
      "labels 1\n",
      "statirical 1\n",
      "vocabilary 1\n",
      "reproving 1\n",
      "unladylike 1\n",
      "niminy 1\n",
      "piminy 1\n",
      "chits 1\n",
      "peacemaker 1\n",
      "tricks 1\n",
      "China 1\n",
      "Aster 1\n",
      "castanets 1\n",
      "ungentle 1\n",
      "tomboy 1\n"
     ]
    }
   ],
   "source": [
    "least_20 = get20LeastFrequentWords(text)\n",
    "print('20 least used words are: ')\n",
    "for word, freq in least_20:\n",
    "    print(word, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "def getChapters(text):\n",
    "    chapters = []\n",
    "    for chapter_text in text.split(\"CHAPTER\"):\n",
    "        chapter = chapter_text[chapter_text.find('\\n'):] \n",
    "        chapter = clean_text(chapter)\n",
    "        if len(chapter) > 0:\n",
    "            chapters.append(chapter)\n",
    "    return chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordFreq(text, word):\n",
    "    freq = 0\n",
    "    for w in text.split(' '):\n",
    "        if w == word:\n",
    "            freq += 1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrequencyOfWord(text, word):\n",
    "    chapters = getChapters(text)\n",
    "    freq = []\n",
    "    for chapter in chapters:\n",
    "        freq.append(getWordFreq(chapter,word))\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of word by chapter:\n",
      "[43, 21, 60, 31, 54, 12, 9, 72, 21, 12, 40, 58, 24, 47, 26, 14, 29, 34, 4, 17, 62, 16, 34, 25, 6, 16, 28, 11, 49, 39, 7, 60, 3, 54, 41, 34, 2, 2, 14, 14, 17, 36, 58, 9, 6, 55, 33]\n"
     ]
    }
   ],
   "source": [
    "freq_by_chapter = getFrequencyOfWord(original_text, 'jo')\n",
    "print('Frequency of word by chapter:')\n",
    "print(freq_by_chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
